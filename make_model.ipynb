{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "smile.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwDSV8CtWwhe",
        "colab_type": "code",
        "outputId": "7ac15e2a-51ba-44ea-df2d-768bb8497745",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# from google.colab import auth\n",
        "# auth.authenticate_user()\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "\n",
        "import numpy as np\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "\n",
        "\n",
        "#r은 단순히 파일을 참조한다는 뜻\n",
        "train_data = h5py.File('gdrive/My Drive/smile_data/train_happy.h5', 'r')\n",
        "test_data = h5py.File('gdrive/My Drive/smile_data/test_happy.h5', 'r')\n",
        "\n",
        "x_train = np.array(train_data['train_set_x'][:])  #이미지\n",
        "y_train = np.array(train_data['train_set_y'][:])  #1 혹은 0 (웃으면 1, 안 웃으면 0)\n",
        "\n",
        "x_test = np.array(test_data['test_set_x'][:])\n",
        "y_test = np.array(test_data['test_set_y'][:])\n",
        "\n",
        "y_train = y_train.reshape((y_train.shape[0], 1))  #(600,1)로 바꿔줌\n",
        "y_test = y_test.reshape((y_test.shape[0], 1))     #(150,1)로 바꿔줌\n",
        "\n",
        "np.save('dataset/x_train_color.npy', x_train)\n",
        "np.save('dataset/x_test_color.npy', x_test)\n",
        "\n",
        "# print(x_train.shape, y_train.shape)\n",
        "# print(x_test.shape, y_test.shape)\n",
        "\n",
        "# 데이터 확인\n",
        "# plt.subplot(2,2,1)\n",
        "# plt.title(y_train[0])\n",
        "# plt.imshow(x_train[0])\n",
        "# plt.subplot(2,2,2)\n",
        "# plt.title(y_train[1])\n",
        "# plt.imshow(x_train[1])\n",
        "# plt.subplot(2,2,3)\n",
        "# plt.title(y_test[0])\n",
        "# plt.imshow(x_test[0])\n",
        "# plt.subplot(2,2,4)\n",
        "# plt.title(y_test[1])\n",
        "# plt.imshow(x_test[1])\n",
        "\n",
        "# x_train 과 x_test 에 들어있는 이미지를 gray scale 로 변환\n",
        "x_result = []\n",
        "for x in x_train:\n",
        "  img = cv2.cvtColor(x, cv2.COLOR_RGB2GRAY)\n",
        "  x_result.append(img)\n",
        "\n",
        "x_result = np.array(x_result)\n",
        "np.save('dataset/x_train.npy', x_result)\n",
        "\n",
        "x_result = []\n",
        "for x in x_test:\n",
        "  img = cv2.cvtColor(x, cv2.COLOR_RGB2GRAY)\n",
        "  x_result.append(img)\n",
        "\n",
        "x_result = np.array(x_result)\n",
        "np.save('dataset/x_test.npy', x_result)\n",
        "\n",
        "# y데이터도 저장\n",
        "np.save('dataset/y_train.npy', y_train)\n",
        "np.save('dataset/y_test.npy', y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgN-XppoG7R5",
        "colab_type": "code",
        "outputId": "663f0fdc-ce52-4f95-e240-d6864addfc5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Conv2D, Dense, Input, MaxPooling2D, Activation, LeakyReLU, Flatten, Dropout\n",
        "from keras.models import Model, Sequential, load_model\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "x_train = np.load('dataset/x_train.npy')\n",
        "y_train = np.load('dataset/y_train.npy')\n",
        "x_test = np.load('dataset/x_test.npy')\n",
        "y_test = np.load('dataset/y_test.npy')\n",
        "\n",
        "# print(x_train.shape, y_train.shape)\n",
        "# print(x_test.shape, y_test.shape)\n",
        "\n",
        "# plt.subplot(1,2,1)\n",
        "# plt.title(y_train[0])\n",
        "# plt.imshow(x_train[0], cmap = 'gray')\n",
        "# plt.subplot(1,2,2)\n",
        "# plt.title(y_train[1])\n",
        "# plt.imshow(x_test[0], cmap = 'gray')\n",
        "\n",
        "x_train = x_train.reshape((-1, 64, 64, 1))\n",
        "x_test = x_test.reshape((-1, 64, 64, 1))\n",
        "\n",
        "train_datagen = ImageDataGenerator( # 데이터 증강 augmentation\n",
        "    samplewise_center = True,       #각 이미지의 평균을 0으로 만듬\n",
        "    samplewise_std_normalization = True,  # 사진의 픽셀들을 사진 전체의 표준편차로 나눔 \n",
        "    #각 사진의 밝기나 스케일이 다르더라도 학습이 쉽도록 도움을 줌\n",
        "    \n",
        "    brightness_range = [0.5, 1.5],  # 원래 밝기를 1로 치고 50퍼센트 어둡게 50퍼센트 밝게\n",
        "    zoom_range = [0.8, 1.1],        # 크기를 0.8에서 1.1까지 임의로 늘리거나 줄임\n",
        "    rotation_range =15.,            #-15도부터 15도까지 이미지 돌림\n",
        "    channel_shift_range = 25,       # channel_shift를 25까지\n",
        "    horizontal_flip = True          # 좌우로 flip\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "    samplewise_center = True,\n",
        "    samplewise_std_normalization = True,\n",
        ")\n",
        "\n",
        "#flow 메서드는 x 데이터와 y 데이터를 batch 단위로 생성할 수 있도록 만드는 것\n",
        "train_batch_gen = train_datagen.flow(x_train, y_train, batch_size = 16, shuffle = True)\n",
        "test_batch_gen = test_datagen.flow(x_test, y_test, batch_size = 16, shuffle = False)\n",
        "\n",
        "#딥러닝 모델 생성\n",
        "inputs = Input(shape = (64, 64, 1)) # 그레이 스케일이니까 channel 1\n",
        "net = Conv2D(filters = 64, kernel_size = 3, strides = 2, padding = 'same')(inputs)\n",
        "net = LeakyReLU()(net)\n",
        "\n",
        "net = Flatten()(net) # 3차원의 배열을 일자로 펴줌\n",
        "\n",
        "net = Dense(units = 64)(net)  #64개짜리 Dense 레이어 사용\n",
        "net = Activation('relu')(net)\n",
        "\n",
        "net = Dense(units = 1)(net)   # output은 1\n",
        "outputs = Activation('sigmoid')(net)\n",
        "\n",
        "model = Model(inputs = inputs, outputs = outputs) #Model 클래스 이용해 실제적인 keras 모델 만들어줌\n",
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['acc'])  #acc은 accuracy\n",
        "\n",
        "model.summary() #모델 모양 조회\n",
        "\n",
        "#모델 학습\n",
        "model.fit_generator(\n",
        "    train_batch_gen, \n",
        "    epochs = 20,\n",
        "    validation_data = test_batch_gen,\n",
        "    callbacks = [ #한 에폭이 끝날 때 마다 실행\n",
        "                 ModelCheckpoint('models/happy.h5', monitor = 'val_acc', save_best_only = True, mode = 'max', verbose = 1), #모델 하나의 에폭이 끝날 때마다 저장\n",
        "                 #validation 의 accuacy를 체크해서 가장 좋은 것만 저장. accuracy가 가장 큰 것만 저장. 저장할 때 프린트\n",
        "                 ReduceLROnPlateau(monitor = 'val_acc', factor = 0.2, patience = 5, verbose = 1, mode = 'auto', min_lr = 1e-05) #running rate 조정\n",
        "                 #validation 의 accuacy를 체크. validation의 accuracy가 높아지지 않아도 5번을 참고 그 이후에도 학습이 안 되면 running rate에 0.1을 곱함\n",
        "                 #최소 running rate는 1e-05까지 \n",
        "    ] \n",
        ")\n",
        "\n",
        "#학습된 모델 검증\n",
        "x_test_input = x_test.copy().astype(np.float64)\n",
        "\n",
        "#normalization 수동으로 하는 것\n",
        "x_test_input -= np.mean(x_test, keepdims=True)  \n",
        "x_test_input /= (np.std(x_test, keepdims=True) + 1e-6)\n",
        "\n",
        "y_pred = model.predict(x_test_input)  # 예측(150개의 아웃풋 생성)\n",
        "\n",
        "y_pred_logical = (y_pred > 0.5).astype(np.int)  #웃은 것은 True(1) 안 웃은 것은 False(0)으로 저장\n",
        "\n",
        "print('test acc : %s' % accuracy_score(y_test, y_pred_logical)) #accuracy_score를 이용해 y_test, y_pred_logical을 비교\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred_logical) #confusion_matrix는 y_test, y_pred_logical을 비교\n",
        "sns.heatmap(cm, annot=True) #confusion_matrix 실제 그리기\n",
        "# 세로 축 : 예측값, 가로축 : 실제 값"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 64, 64, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 64)        640       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 65536)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                4194368   \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 65        \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 4,195,073\n",
            "Trainable params: 4,195,073\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "38/38 [==============================] - 15s 390ms/step - loss: 0.8864 - acc: 0.5872 - val_loss: 0.6813 - val_acc: 0.5200\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.52000, saving model to models/happy.h5\n",
            "Epoch 2/20\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.5941 - acc: 0.6579 - val_loss: 0.6440 - val_acc: 0.6800\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.52000 to 0.68000, saving model to models/happy.h5\n",
            "Epoch 3/20\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.5727 - acc: 0.6958 - val_loss: 0.5540 - val_acc: 0.6600\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.68000\n",
            "Epoch 4/20\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.5339 - acc: 0.7187 - val_loss: 0.4909 - val_acc: 0.7400\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.68000 to 0.74000, saving model to models/happy.h5\n",
            "Epoch 5/20\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.5134 - acc: 0.7517 - val_loss: 0.5545 - val_acc: 0.7133\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.74000\n",
            "Epoch 6/20\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.5173 - acc: 0.7319 - val_loss: 0.4484 - val_acc: 0.8133\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.74000 to 0.81333, saving model to models/happy.h5\n",
            "Epoch 7/20\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.4215 - acc: 0.8026 - val_loss: 0.5229 - val_acc: 0.7733\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.81333\n",
            "Epoch 8/20\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.4440 - acc: 0.7895 - val_loss: 0.4461 - val_acc: 0.7467\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.81333\n",
            "Epoch 9/20\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.4556 - acc: 0.7697 - val_loss: 0.3970 - val_acc: 0.8267\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.81333 to 0.82667, saving model to models/happy.h5\n",
            "Epoch 10/20\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.4040 - acc: 0.8158 - val_loss: 0.3544 - val_acc: 0.8267\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.82667\n",
            "Epoch 11/20\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.3524 - acc: 0.8454 - val_loss: 0.3691 - val_acc: 0.8267\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.82667\n",
            "Epoch 12/20\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.3910 - acc: 0.8273 - val_loss: 0.2813 - val_acc: 0.8800\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.82667 to 0.88000, saving model to models/happy.h5\n",
            "Epoch 13/20\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.4119 - acc: 0.8125 - val_loss: 0.3967 - val_acc: 0.8133\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.88000\n",
            "Epoch 14/20\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.3738 - acc: 0.8421 - val_loss: 0.3167 - val_acc: 0.8800\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.88000\n",
            "Epoch 15/20\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.3464 - acc: 0.8569 - val_loss: 0.2683 - val_acc: 0.9067\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.88000 to 0.90667, saving model to models/happy.h5\n",
            "Epoch 16/20\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.3203 - acc: 0.8504 - val_loss: 0.3850 - val_acc: 0.8200\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.90667\n",
            "Epoch 17/20\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.2982 - acc: 0.8947 - val_loss: 0.3167 - val_acc: 0.8533\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.90667\n",
            "Epoch 18/20\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.3166 - acc: 0.8652 - val_loss: 0.3140 - val_acc: 0.8467\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.90667\n",
            "Epoch 19/20\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.3151 - acc: 0.8634 - val_loss: 0.2214 - val_acc: 0.9200\n",
            "\n",
            "Epoch 00019: val_acc improved from 0.90667 to 0.92000, saving model to models/happy.h5\n",
            "Epoch 20/20\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.2596 - acc: 0.8849 - val_loss: 0.2312 - val_acc: 0.9133\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.92000\n",
            "test acc : 0.9066666666666666\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f00cc2a69e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAD4CAYAAACt8i4nAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAkCw/wfKyebk5o99LgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}